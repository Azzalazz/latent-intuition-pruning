# Latent Intuition Pruning

*A real-time adaptive algorithm that prunes decision trees based on subtle user behaviors like hesitation, hover time, and interest fading.*

---

## ğŸ” Problem Statement & Use Case

Most applications only respond to explicit user choices (like clicks), but subtle behaviors like pausing, hovering, or returning to certain content often reveal more about a userâ€™s interests. This project introduces a novel adaptive search algorithmâ€”**Latent Intuition Pruning**â€”that uses real-time behavioral cues to explore a decision tree more intelligently. Itâ€™s especially useful in systems like interactive content recommenders, exploratory design tools, or UX prototypes that offer many options but want to minimize irrelevant choices.

---

## âš™ï¸ Algorithm Overview

**Latent Intuition Pruning (LIP)** dynamically adapts tree traversal based on:
- **Hover/interest duration** (user hesitation or attention)
- **Temporal decay** (older interest fades over time)
- **Depth-awareness** (accounts for cognitive cost of deep branches)
- **Îµ-Greedy exploration** (adds occasional randomness for discovery)

This is done without any machine learning models or training phase, making it lightweight, interpretable, and testable in real-time.

---

## ğŸ’¡ Key Features

- âœ… **User-Driven Scoring** â€“ Uses simulated hover data to score nodes
- â³ **Interest Decay** â€“ Scores gradually fade as time passes
- ğŸ² **Îµ-Greedy Randomness** â€“ Occasionally explores less likely branches
- ğŸ“‰ **Depth-Aware Scoring** â€“ Penalizes deep paths without strong interest
- ğŸ§  **No ML Dependency** â€“ All adaptation is rule-based and transparent

---

## ğŸ§ª Evaluation & Test Plan

We simulate a user interacting with a decision tree:
- Hover times are assigned to various nodes
- Adaptive pruning runs from the root and logs the visited nodes
- Compared against a **baseline DFS** to show improved prioritization

### âœ”ï¸ Example Test Cases
- **Test 1**: User hovers on â€œExplore Beachesâ€ and â€œSurfing Spotsâ€ â†’ LIP prioritizes those
- **Test 2**: Tie between two interests â†’ LIP explores both, adaptively
- **Test 3**: Minimal interest given â†’ LIP still visits all paths like DFS

See `test_cases.py` for details. All test cases pass and output expected paths.

---

## ğŸ“ˆ Runtime & Space Complexity

- **Traversal Time**: O(n log d), where d = average branching factor
- **Per-node Work**: O(log d) due to sorting children
- **Memory**: O(n) for tracking visited nodes and scores

Profiling with `time` module and logging included in `main.py`.

---

## ğŸ“‚ Project Structure

| File | Purpose |
|------|---------|
| `main.py` | Runs full simulation with pruning, scoring, and logs |
| `latent_intuition_pruning.py` | Core algorithm: scoring, decay, and tree logic |
| `baseline_dfs.py` | Standard DFS for performance comparison |
| `test_cases.py` | Contains 3+ unit tests validating pruning behavior |
| `README.md` | This document |

---

## â–¶ï¸ Run Instructions

```bash
python main.py           # Runs the adaptive pruning system
python baseline_dfs.py   # Runs baseline DFS (no heuristics)
python test_cases.py     # Executes unit tests (3+ cases)
```

No external dependencies required (just Python 3.x).

---

## ğŸ”– Git Tag for Grading

Final submission version is tagged as:  
**`v1.0-final`**  
[Link to Release](https://github.com/YOUR_USERNAME/YOUR_REPO/releases/tag/v1.0-final)

---

## ğŸ¥ Optional Demo Video (Coming Soon)

I will include a brief 1â€“3 min screencast demonstrating:
- The traversal paths with and without pruning
- Hover-based adaptation in real time
- Comparison results in logs

Link will be added here upon upload.

